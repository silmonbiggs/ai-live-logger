# ChatGPT and Claude Pipeline Logic and Filtering - Method Notes

## Section 1: ChatGPT Pipeline

## Overview
The ChatGPT handler captures user inputs and assistant responses from ChatGPT conversations, with sophisticated filtering to prevent duplicates and UI noise from being logged.

## Architecture Flow
1. User types in ChatGPT → Browser captures input → Extension logs
2. ChatGPT responds → DOM mutation observer detects → Extension processes → Extension logs
3. Background script receives messages → POSTs to localhost:8788 server
4. Server writes to chat.log in JSON format

## Key Components

### 1. User Input Capture (setupUserCapture)
**Multiple capture methods for reliability:**
- `input` event listener on textareas/contenteditable elements
- `keydown` listener for Enter key (non-Shift+Enter)
- `click` listener on send buttons
- `submit` listener on forms
- Fallback selector-based capture with 200ms delay

**Input processing:**
- Tracks `currentUserText` during typing
- Uses `normText()` to clean whitespace
- Prevents duplicate user messages via `lastUserText` comparison
- Minimum 2 character length requirement

### 2. Assistant Response Detection (setupResponseDetection)
**DOM observation strategy:**
- MutationObserver on document.body with `childList: true, subtree: true, characterData: true`
- Detects both new nodes and character data changes (for streaming)
- Uses platform-specific selectors to identify assistant message containers

**Streaming handling:**
- Debounced capture with 2500ms delay for streaming responses
- `pendingCaptures` Map to manage multiple concurrent streaming messages
- Special handling for streaming updates vs new messages

### 3. Multi-Layer Filtering System

#### 3.1 Basic Validation
- Skip empty or very short content (< 3 chars)
- Skip nodes already processed (tracked in `assistantNodes` Set)
- 10-second startup grace period to avoid capturing stale content

#### 3.2 UI Noise Filtering (`isUINoiseContent`)
**Whitelist approach for known content containers:**
- Allow content from `.markdown`, `.prose`, `.text-token-text-primary` classes
- Filter common UI elements: copy, regenerate, share, edit, retry buttons
- Filter pagination indicators, navigation elements
- Skip content in UI chrome (nav, header, sidebar, toolbar) unless in message context

#### 3.3 Platform-Specific Noise Filtering
- **Thinking noise**: "ChatGPT said: Thinking", "Thought for X seconds"
- **Echo noise**: "You said:" prefixes and repetitions
- **Feedback noise**: Response preference UI, comparison interfaces
- **Streaming placeholders**: Incomplete "ChatGPT said:" without content

#### 3.4 Duplicate Detection (Recent History Buffer)
**Problem solved:** Previous logic only compared against immediate last message, missing duplicates separated by other messages (e.g., "okay904" → "okay905" → "okay904" duplicate)

**Solution implemented:**
- `recentAssistantMessages[]` buffer storing last 20 assistant messages
- `isDuplicateInRecentHistory()` checks new message against entire buffer
- Handles both exact matches and "ChatGPT said:" prefix variations
- `addToRecentHistory()` maintains sliding window of exactly 20 messages

### 4. Text Cleaning Pipeline (`cleanAssistantText`)
**Current cleaning steps:**
1. Remove "ChatGPT said:" prefixes
2. Remove conversation metadata like "ChatGPT:" or "GPT-4:"
3. Trim whitespace

**Note:** Less aggressive than Claude cleaning to preserve ChatGPT's simpler response format

### 5. Message Payload Creation
**Metadata included:**
- Platform: "chatgpt"
- Role: "user" or "assistant"
- Timestamp in ISO format
- Message length
- URLs extracted from text
- Streaming indicator
- Empty artifacts array (ChatGPT doesn't have artifacts like Claude)

## Critical Implementation Details

### Startup Behavior
- 10-second grace period after extension load/reload to prevent stale content capture
- Test message sent 2 seconds after initialization to verify server connection
- Extension must be reloaded AND ChatGPT page refreshed for changes to take effect

### Error Handling
- Try-catch blocks around all major operations
- Fallback handler when platform-specific handlers fail
- Graceful degradation with console logging for debugging

### Performance Considerations
- Debounced streaming capture (2500ms) to avoid excessive API calls
- Limited assistant node tracking to prevent memory leaks
- Recent history buffer capped at 20 messages to prevent memory bloat
- Selector caching and efficient DOM querying

## Key Lessons for Claude Pipeline

### 1. Duplicate Detection Must Use History Buffer
Single `lastAssistantText` comparison is insufficient. Use sliding window of recent messages.

### 2. Streaming Requires Debouncing
Don't log every character change during streaming responses. Use timeout-based debouncing.

### 3. Platform-Specific Filtering is Essential
Each platform has unique UI patterns and noise. Generic filtering won't suffice.

### 4. Startup Grace Period Prevents Stale Capture
Essential for avoiding capture of existing conversation history when extension loads.

### 5. Multiple Input Capture Methods Needed
No single method captures all user inputs reliably. Layer multiple approaches.

### 6. Whitelist > Blacklist for Content Detection
Prefer allowing known good containers rather than trying to block all possible UI noise.

## Common Failure Modes and Solutions

### Problem: Duplicates appearing hours apart
**Solution:** Recent history buffer with appropriate window size (20 messages = ~1-2 hours of conversation)

### Problem: UI elements being logged as responses
**Solution:** Whitelist known content containers, blacklist UI chrome selectors

### Problem: Streaming responses creating multiple log entries
**Solution:** Debounced capture with pendingCaptures management

### Problem: Missing user inputs on various trigger methods
**Solution:** Multiple capture strategies (events + polling + selectors)

### Problem: Extension changes not taking effect
**Solution:** Both extension reload AND page refresh required due to content script injection timing

## Testing Methodology
1. Reload extension in chrome://extensions
2. F5 refresh ChatGPT tab (essential!)
3. Wait 10+ seconds for startup grace period
4. Test with numbered messages to track sequence
5. Verify both user inputs and responses are captured
6. Test duplicate scenarios with intervening messages
7. Check console logs for filtering decisions

## File Structure
- `chatgpt_handler.js` - Main platform handler
- `common.js` - Shared utilities and message creation
- `content.js` - Platform router and fallback handler
- `bg.js` - Background script for server communication
- Server logs to `chat.log` in JSON format

---

## Section 2: Claude Pipeline

### Overview
The Claude handler uses an advanced signal processing architecture designed to handle Claude's complex conversation behavior, including conversation history retransmissions, streaming responses, and sophisticated duplicate detection. Unlike ChatGPT's simpler approach, Claude requires multi-layer filtering due to its tendency to retransmit existing conversation content.

### Architecture Flow
1. User types in Claude → Browser captures input → Extension logs
2. Claude responds (often with streaming) → Debounced DOM observation → Signal processing filters → Extension logs
3. Background script receives messages → POSTs to localhost:8788 server
4. Server writes to chat.log in JSON format

### Key Architectural Differences from ChatGPT
- **Shorter debounce delay**: 50ms vs ChatGPT's 2500ms for faster streaming capture
- **Signal processing**: 5-layer filtering system to handle Claude's retransmission behavior
- **Conversation baseline**: Establishes existing conversation content to avoid logging old messages
- **Advanced text extraction**: TreeWalker approach to avoid phantom DOM elements
- **Musical command preservation**: Special handling for ChurnRoom use case

## Key Components

### 1. User Input Capture (setupUserCapture)
**Enhanced send detection system:**
- Similar event listeners to ChatGPT (input, keydown, click, submit)
- `onUserSendMessage()` callback with user send tracking state
- Enhanced user interaction timestamps for temporal filtering
- User activity window tracking (2 minutes) for signal processing

**User send tracking state:**
- `awaitingResponse`: Boolean flag when user has sent a message
- `responseToContent`: Content of the user's message awaiting response
- `userSentAt`: Timestamp of when user sent message
- `responseWindow`: 15-second window to expect legitimate response

### 2. Response Detection (setupResponseDetection)
**Debounced streaming capture:**
- MutationObserver with 50ms debounce delay (much shorter than ChatGPT)
- `handleNodeWithDebounce()` manages pending message timers
- Re-extracts text after debounce period to catch streaming completion
- Exposes debugging interface (`debouncedCapture.getPendingMessages()`)

**Advanced node processing:**
- `processNewNode()` applies 5-layer signal processing
- Context tracking for debounced vs immediate processing
- Text change detection during debounce period

### 3. Signal Processing Filters (5-Layer System)

#### Layer 1: Velocity Filter (`passesVelocityFilter`)
**Purpose:** Detect bulk message dumps and conversation history retransmissions
- Tracks message timestamps in `velocityBuffer`
- Threshold: 5 messages per second triggers filter
- Window: 1000ms rolling window
- **Blocks:** Rapid-fire message sequences that indicate retransmission

#### Layer 2: Temporal Filter (`passesTemporalFilter`)
**Purpose:** Validate messages occur within reasonable conversation context
- Checks time since last user interaction (2-minute window)
- Allows messages in conversation baseline (existing content)
- **Blocks:** Messages appearing without recent user activity (phantom responses)

#### Layer 3: Autocorrelation Filter (`passesAutocorrelationFilter`)
**Purpose:** Detect repeated patterns in message sequences
- Maintains `hashBuffer` of recent message hashes (20 messages)
- Compares recent hashes against older patterns
- Threshold: 3+ pattern matches triggers filter
- **Blocks:** Systematic repetition patterns in conversation dumps

#### Layer 4: Echo Filter (`passesEchoFilter`)
**Purpose:** Detect exact duplicate messages
- Maps message text to timestamps in `processedMessages`
- Allows recent echoes (30-second window) for legitimate conversation flow
- **Blocks:** Exact duplicates outside legitimate repeat window

#### Layer 5: Contextual Preservation (`shouldPreserveByContext`)
**Purpose:** Allow legitimate repeated content
- **Musical commands**: Preserves PLAY:, STOP, VOLUME: commands for ChurnRoom
- **Legitimate responses**: Allows responses within user interaction window
- **User-driven repeats**: Preserves content when user is awaiting response

### 4. Text Extraction (`extractCleanText`)
**Advanced TreeWalker approach:**
- Avoids phantom DOM elements that caused "J" prefix issues
- Filters hidden/invisible elements via computed styles
- Skips buttons, icons, and UI elements
- More reliable than simple `textContent` extraction

**Problem solved:** ChatGPT's simple text extraction was picking up UI artifacts

### 5. Conversation Baseline (`establishConversationBaseline`)
**Purpose:** Prevent logging of existing conversation history
- Scans existing message containers on initialization
- Builds `conversationBaseline` Set of existing content
- Used by temporal and echo filters to allow existing content
- **Essential** for avoiding duplicate logging when extension loads

### 6. Message Payload Creation
**Claude-specific metadata:**
- Platform: "claude"
- Artifacts: Uses `captureClaudeArtifacts()` for code blocks, previews
- Tools: Detects Claude-specific tools (thinking, computer_use, bash, python)
- Debounce information: Tracks whether message was debounced and delay
- Text change tracking: Notes if content changed during debounce period

## Filter Configuration
```javascript
filterConfig: {
  velocityThreshold: 5,           // Messages per second threshold
  velocityWindow: 1000,           // 1 second window
  conversationWindow: 300000,     // 5 minutes
  userActivityWindow: 120000,     // 2 minutes
  hashBufferSize: 20,             // Pattern detection buffer
  patternThreshold: 3,            // Pattern match threshold
  musicalCommandWindow: 60000,    // ChurnRoom use case
  legitimateRepeatWindow: 30000,  // Legitimate echo window
  persistenceThreshold: 500       // Message persistence
}
```

## Current Issues (As of Last Analysis)

### Assistant Response Detection Failure
**Symptom:** User inputs captured successfully, but no assistant responses logged
**Evidence from console logs:**
- User input: ✅ "How are you tonight, Claude?" captured and sent
- Assistant response: ❌ No detection/processing logs whatsoever
- MutationObserver: ❌ No evidence of response node detection

**Potential causes:**
1. **Outdated selectors**: Claude's DOM structure changed, breaking assistant message detection
2. **Over-aggressive filtering**: Response getting blocked by one of the 5 filter layers
3. **MutationObserver issues**: Not detecting Claude's response containers as mutations
4. **Startup grace period**: 10-second filter blocking legitimate new responses
5. **Debounce timing**: 50ms may be too short for Claude's current streaming behavior

### Assistant Selectors (May Need Updates)
Current selectors in `config.assistantSelectors`:
- `[data-role="assistant"]`
- `[data-message-role="assistant"]`
- `.claude-message`
- `div[role="article"]`
- `main div[class*="prose"]`
- Various generic selectors

**Investigation needed:** Check if Claude's current DOM structure uses different attributes/classes

## Performance Characteristics

### Memory Management
- `conversationBaseline` Set grows with conversation length
- `processedMessages` Map tracks all seen messages (potential memory leak)
- `hashBuffer` limited to 20 messages
- `velocityBuffer` auto-cleans timestamps older than 1 second

### Processing Overhead
- 5-layer filtering adds computational cost vs ChatGPT's simpler approach
- TreeWalker text extraction more CPU-intensive than simple textContent
- Debounce timers create overhead for rapid message streams
- Signal processing statistics tracking adds memory overhead

## Debugging Tools

### Built-in Debug Interface
- `debouncedCapture.getPendingMessages()` - Shows pending debounced messages
- `debouncedCapture.clearPending()` - Clears all pending timers
- `state.stats` - Comprehensive filtering statistics
- Console logging for each filter layer decision

### Filter Statistics Tracking
```javascript
stats: {
  totalMessages: 0,
  filteredByVelocity: 0,
  filteredByTemporal: 0,
  filteredByEcho: 0,
  filteredByAutocorrelation: 0,
  preservedByContext: 0,
  cleanLogEntries: 0,
  verboseLogEntries: 0
}
```

## Testing Methodology for Claude
1. Reload extension in chrome://extensions
2. F5 refresh Claude tab (**critical** - more so than ChatGPT due to baseline establishment)
3. Wait 10+ seconds for startup grace period AND baseline establishment
4. Test with conversational messages (not just "okay" test patterns)
5. Check console for signal processing filter decisions
6. Monitor `state.stats` for filter effectiveness
7. Verify both user inputs and responses captured

## Key Differences Summary: Claude vs ChatGPT

| Aspect | ChatGPT | Claude |
|--------|---------|---------|
| **Debounce delay** | 2500ms | 50ms |
| **Filtering** | 3-layer (basic, UI, platform) | 5-layer signal processing |
| **Text extraction** | Simple textContent | TreeWalker with style filtering |
| **Duplicate detection** | Recent history buffer (20) | Multi-layer (echo, velocity, pattern) |
| **Baseline** | None | Conversation baseline establishment |
| **Startup behavior** | 10s grace period | 10s grace + baseline scan |
| **Memory usage** | Low | Higher (signal processing state) |
| **CPU usage** | Low | Higher (filtering computation) |
| **Artifact support** | None | Advanced artifact detection |

## Recommended Next Steps
1. **Investigate assistant selectors** - Check if Claude's DOM changed
2. **Review MutationObserver scope** - Ensure it's detecting Claude responses
3. **Analyze filter statistics** - Check if responses are being filtered out
4. **Test with simpler selectors** - Temporarily use broader selectors for debugging
5. **Add more debug logging** - Increase visibility into response detection pipeline